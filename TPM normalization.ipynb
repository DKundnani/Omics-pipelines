{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python3\n",
    "#Author: Deepali L. Kundnani\n",
    "#Institution: Georgia Institute of Technology (Georgia Tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages needed to be imported and input files need to be processed using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Getting TPM values from counts')\n",
    "#parser.add_argument('--filename', default='exons_pc.counts', help=\"counts file, output from feature counts\")\n",
    "#parser.add_argument(\"-r\", \"--referencefasta\" ,required=True, default='/storage/home/hcoda1/5/dkundnani3/p-fstorici3-0/rich_project_bio-storici/reference/sacCer2/sacCer2.fa', help=\"Specify the fasta file for reference of the sequenced Libraries. Make sure you have Ribosemap environment activated or have bedtools available to be used\") \n",
    "#args= parser.parse_args()\n",
    "\n",
    "#counts='GSE139242_CD4_counts.csv'\n",
    "#counts='GSE175070_H9_counts.tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions required to convert counts to tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filterchr(df,col):\n",
    "    \"\"\"\n",
    "    Filter out X and Y chromosomes\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A DataFrame containing necesarry details. Rows represent genomic regions, columns represent samples.\n",
    "    col (num): Column index containing chromosome names\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with required chromosomes\n",
    "    \"\"\"\n",
    "    filtered_df = df[~df.iloc[:,col].str.contains('chrX|chrY|chrM')]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def convert_counts_to_tpm(df, gene_lengths):\n",
    "    \"\"\"\n",
    "    Convert raw RNA-seq counts to TPM.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A DataFrame containing RNA-seq counts. Rows represent genes, columns represent samples.\n",
    "    gene_lengths (pd.Series): A Series containing the gene lengths in base pairs. The index should match the DataFrame index.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with TPM values.\n",
    "    \"\"\"\n",
    "    # Step 0: Covert dataframes to float before any calculations\n",
    "    df = df.astype(float) ; gene_lengths = gene_lengths.astype(float)\n",
    "    \n",
    "    # Step 1: Convert gene lengths from base pairs to kilobases\n",
    "    gene_lengths_kb = gene_lengths / 1000\n",
    "    \n",
    "    # Step 2: Compute Reads Per Kilobase (RPK)\n",
    "    rpk = df.div(gene_lengths_kb, axis=0)\n",
    "    \n",
    "    # Step 3: Compute scaling factor (sum of RPKs per sample)\n",
    "    scaling_factors = rpk.sum(axis=0)\n",
    "    \n",
    "    # Step 4: Calculate TPM\n",
    "    tpm = rpk.div(scaling_factors, axis=1) * 1e6\n",
    "    \n",
    "    return tpm\n",
    "\n",
    "\n",
    "def convert_counts_to_rpkm(df, gene_lengths):\n",
    "    \"\"\"\n",
    "    Convert raw RNA-seq counts to TPM.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A DataFrame containing RNA-seq counts. Rows represent genes, columns represent samples.\n",
    "    gene_lengths (pd.Series): A Series containing the gene lengths in base pairs. The index should match the DataFrame index.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with TPM values.\n",
    "    \"\"\"\n",
    "    # Step 0: Covert dataframes to float before any calculations\n",
    "    df = df.astype(float) ; gene_lengths = gene_lengths.astype(float)\n",
    "\n",
    "    # Step 1: Compute scaling factor (sum of counts per sample)\n",
    "    scaling_factors = df.sum(axis=0)\n",
    "    \n",
    "    # Step 3: Compute Reads Per Million (RPM)\n",
    "    rpm = df.div(scaling_factors, axis=1) * 1e6\n",
    "    \n",
    "    # Step 4: Convert gene lengths from base pairs to kilobases\n",
    "    gene_lengths_kb = gene_lengths / 1000\n",
    "\n",
    "    # Step 5: Calculate RPKM\n",
    "    rpkm = rpm.div(gene_lengths_kb, axis=0) \n",
    "    \n",
    "    return rpkm\n",
    "\n",
    "\n",
    "# Remove the top and bottom 5% of outliers from each column in tpm_df\n",
    "def remove_outliers(df, lower_percentile=0.05, upper_percentile=0.95):\n",
    "    \"\"\"\n",
    "    Removes outliers based on percentiles.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    lower_percentile (float): Lower percentile threshold (default: 0.05).\n",
    "    upper_percentile (float): Upper percentile threshold (default: 0.95).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    filtered_df = df.apply(\n",
    "        lambda x: x[(x >= x.quantile(lower_percentile)) & (x <= x.quantile(upper_percentile))],\n",
    "        axis=0\n",
    "    )\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read counts file\n",
    "counts_df = pd.read_csv('exonspc.counts', sep='\\t',skiprows=1)\n",
    "samples=counts_df.columns[6:counts_df.shape[1]].values\n",
    "# Filtere Chromosome X, Y and M\n",
    "counts_df = filterchr(counts_df,1)\n",
    "min_count = 10  # Minimum count threshold\n",
    "min_samples = len(samples)/2  # Minimum number of samples that must meet the threshold\n",
    "# Convert counts to TPM\n",
    "tpm_df = convert_counts_to_tpm(counts_df[samples], counts_df[['Length']].values)\n",
    "# Merge TPM with Original file\n",
    "merged_df = pd.concat([counts_df.iloc[:,0:6], tpm_df], axis=1)\n",
    "# Save the TPM file for merging with other files\n",
    "merged_df.to_csv('HEK_tpm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read counts file\n",
    "counts_df = pd.read_csv('exonspc.counts', sep='\\t', skiprows=1)\n",
    "samples=counts_df.columns[6:counts_df.shape[1]].values\n",
    "# Filter out X and Y chromosomes\n",
    "counts_df = filterchr(counts_df, 0)\n",
    "# Define filtering criteria\n",
    "#min_count = 10  # Minimum count threshold\n",
    "#min_samples = len(samples)/2  # Minimum number of samples that must meet the threshold\n",
    "# Apply filtering\n",
    "#counts_df = counts_df[(counts_df[samples] > min_count).sum(axis=1) >= min_samples]\n",
    "# Convert counts to TPM & RPKM\n",
    "tpm_df = convert_counts_to_tpm(counts_df[samples], counts_df[['Length']].values)\n",
    "rpkm_df = convert_counts_to_rpkm(counts_df[samples], counts_df[['Length']].values)\n",
    "#Converting the values to log2\n",
    "#tpm_df = tpm_df.map(lambda x: 0 if x == 0 else np.log2(x))\n",
    "#rpkm_df = rpkm_df.map(lambda x: 0 if x == 0 else np.log2(x))\n",
    "# Save the TPM file for merging with other files\n",
    "# Merge TPM with Original file\n",
    "merged_df = pd.concat([counts_df.iloc[:,0:6], tpm_df], axis=1)\n",
    "# Save the TPM file for merging with other files\n",
    "merged_df.to_csv('HEK_tpm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Length'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m samples\u001b[38;5;241m=\u001b[39mcounts_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:counts_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define filtering criteria\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#min_count = 10  # Minimum count threshold\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#min_samples = len(samples)/2  # Minimum number of samples that must meet the threshold\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Apply filtering\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#counts_df = counts_df[(counts_df[samples] > min_count).sum(axis=1) >= min_samples]\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert counts to TPM & RPKM\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m tpm_df \u001b[38;5;241m=\u001b[39m convert_counts_to_tpm(counts_df[samples], \u001b[43mcounts_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLength\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     10\u001b[0m rpkm_df \u001b[38;5;241m=\u001b[39m convert_counts_to_rpkm(counts_df[samples], counts_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLength\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Converting the values to log2\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#tpm_df = tpm_df.map(lambda x: 0 if x == 0 else np.log2(x))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#rpkm_df = rpkm_df.map(lambda x: 0 if x == 0 else np.log2(x))\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Save the TPM file for merging with other files\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Length'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "counts_df = pd.read_csv('GSE139242_CD4T_protein.counts', sep='\\t', header=0, index_col=0)\n",
    "samples=counts_df.columns[1:counts_df.shape[1]].values\n",
    "# Define filtering criteria\n",
    "#min_count = 10  # Minimum count threshold\n",
    "#min_samples = len(samples)/2  # Minimum number of samples that must meet the threshold\n",
    "# Apply filtering\n",
    "#counts_df = counts_df[(counts_df[samples] > min_count).sum(axis=1) >= min_samples]\n",
    "# Convert counts to TPM & RPKM\n",
    "tpm_df = convert_counts_to_tpm(counts_df[samples], counts_df[['Length']].values)\n",
    "rpkm_df = convert_counts_to_rpkm(counts_df[samples], counts_df[['Length']].values)\n",
    "#Converting the values to log2\n",
    "#tpm_df = tpm_df.map(lambda x: 0 if x == 0 else np.log2(x))\n",
    "#rpkm_df = rpkm_df.map(lambda x: 0 if x == 0 else np.log2(x))\n",
    "# Save the TPM file for merging with other files\n",
    "tpm_df.to_csv('CD4T_tpm.csv', index=True)\n",
    "rpkm_df.to_csv('CD4T_rpkm.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to tpm_df\n",
    "#tpm_df = remove_outliers(tpm_df)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Apply min-max scaling to tpm_df\n",
    "tpm_df_scaled = pd.DataFrame(scaler.fit_transform(tpm_df), columns=tpm_df.columns, index=tpm_df.index)\n",
    "\n",
    "\n",
    "from scipy.stats import zscore\n",
    "# Apply z-score normalization to tpm_df\n",
    "tpm_df_zscore = tpm_df.apply(zscore, axis=0)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# Apply decimal scaling to tpm_df\n",
    "tpm_df_decimal_scaled = tpm_df.apply(lambda x: x / (10 ** np.ceil(np.log10(x.abs().max()))), axis=0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Initialize the RobustScaler\n",
    "scaler = RobustScaler()\n",
    "# Apply robust scaling to tpm_df\n",
    "tpm_df_robust_scaled = pd.DataFrame(scaler.fit_transform(tpm_df), columns=tpm_df.columns, index=tpm_df.index)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Initialize the QuantileTransformer\n",
    "quantile_transformer = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "\n",
    "# Apply percentile transformation to tpm_df\n",
    "tpm_df_percentile = pd.DataFrame(\n",
    "    quantile_transformer.fit_transform(tpm_df),\n",
    "    columns=tpm_df.columns,\n",
    "    index=tpm_df.index\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CD4_bloodinfant'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m tpm_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Assign color based on sample type\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     color \u001b[38;5;241m=\u001b[39m \u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     17\u001b[0m     sns\u001b[38;5;241m.\u001b[39mkdeplot(tpm_df[column], label\u001b[38;5;241m=\u001b[39mcolumn, color\u001b[38;5;241m=\u001b[39mcolor, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverlapping KDE Plots for TPM Values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CD4_bloodinfant'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Define color mapping\n",
    "colors = {\n",
    "    'HEK293T_WT': '#D62728',\n",
    "    'HEK293T_KO_T3_8': '#E377C2',\n",
    "    'HEK293T_KO_T3_17': '#9467BD', \n",
    "    'H9': '#2CA02C',\n",
    "    'CD4T': '#FF7F0E',\n",
    "}\n",
    "\n",
    "# Generate overlapping KDE plots for each column in tpm_df\n",
    "plt.figure(figsize=(10, 8))\n",
    "for column in tpm_df.columns:\n",
    "    # Assign color based on sample type\n",
    "    color = colors[column[:-2]]\n",
    "    sns.kdeplot(tpm_df[column], label=column, color=color, fill=False, alpha=0.5)\n",
    "\n",
    "plt.title('Overlapping KDE Plots for TPM Values')\n",
    "plt.xlabel('TPM Values')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc='upper right', fontsize='small', bbox_to_anchor=(1.25, 1))\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate overlapping KDE plots for each column in tpm_df\n",
    "plt.figure(figsize=(10, 8))\n",
    "for column in tpm_df_scaled.columns:\n",
    "    # Assign color based on sample type\n",
    "    color = colors[column[:-2]]\n",
    "    sns.kdeplot(tpm_df_scaled[column], label=column, color=color, fill=False, alpha=0.5)\n",
    "\n",
    "plt.title('Overlapping KDE Plots for TPM Values')\n",
    "plt.xlabel('RPKM Values')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc='upper right', fontsize='small', bbox_to_anchor=(1.25, 1))\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking averages for each cell type\n",
    "\n",
    "merged_df['HEK293T-KO-T3-17'] = merged_df.filter(like='HEK293T-KO-T3-17').mean(axis=1)\n",
    "merged_df['HEK293T-KO-T3-8'] = merged_df.filter(like='HEK293T-KO-T3-8').mean(axis=1)\n",
    "merged_df['HEK293T-WT'] = merged_df.filter(like='HEK293T-WT').mean(axis=1)\n",
    "\n",
    "# Saving average TPM file\n",
    "merged_df[['Geneid','HEK293T-WT','HEK293T-KO-T3-8','HEK293T-KO-T3-17']].to_csv('HEK_tpm_avg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGS counts analysis\n",
    "counts_df = pd.read_csv('AGS_rnaseq_counts.tsv', sep='\\t')\n",
    "samples=counts_df.columns[0:7].values\n",
    "tpm_df = convert_counts_to_tpm(counts_df[samples], counts_df[['Length']].values)\n",
    "merged_df = pd.concat([counts_df.iloc[:,7:counts_df.shape[1]], tpm_df], axis=1)\n",
    "merged_df.to_csv('AGS_tpm.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'A1BG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Correlation matrix of dataframe merged df\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcounts_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcounts_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'A1BG'"
     ]
    }
   ],
   "source": [
    "# Correlation matrix of dataframe merged df\n",
    "counts_df.iloc[:,6:counts_df.shape[1]].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
